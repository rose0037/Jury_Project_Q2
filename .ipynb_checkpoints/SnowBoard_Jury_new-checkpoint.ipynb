{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "################### Old Data Set ###################\n",
    "\n",
    "\n",
    "data = pd.read_csv('jury_data.csv', encoding= 'ISO-8859-1', skiprows=[0,2])\n",
    "data.rename(columns={\"Was defendant Mesa Management negligent?\": \"Mesa_Negligent\", \n",
    "                         \"Was Mesa Management's negligence a substantial factor in causing harm to  Mackenzie Dunn?\":\"Liability\",\n",
    "                         \"What are the total damages that you find that MacKenzie Dunn sufferered?\":\"damages\" ,\n",
    "                         \"What is your sex?\": \"gender\",\n",
    "                         \"Please write your answer to the preceding damages question in words (quality check).\":\"damages_word\",\n",
    "                         \"What percentage of responsibility for Mackenzie Dunn's injuries was each party responsible for? (Answers should add up to 100%) - Mesa Management Co\":\"Mesa_reponsible_percentage\",\n",
    "                         \"Path\":\"Scenario\",\n",
    "                         \"Was MacKenzie Dunn negligent?\":\"Dunn_negligent\",\n",
    "                         \"Unnamed: 63\":\"perc_calc\"\n",
    "                         },inplace=True)\n",
    "data['mm_perc'] = np.where(data['Mesa_reponsible_percentage']>=1, data['perc_calc'], data['Mesa_reponsible_percentage'])\n",
    "req_data = pd.DataFrame(data[[\"Mesa_Negligent\",\"damages\",\"Liability\",\n",
    "                 \"gender\",\n",
    "                 \"damages_word\",\n",
    "                 \"Scenario\",\"Dunn_negligent\",\"perc_calc\",\"Start Date\",\"End Date\",\"mm_perc\"]])\n",
    "\n",
    "\n",
    "req_data['Liability'] = req_data['Liability'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "print(req_data.columns)\n",
    "\n",
    "\n",
    "\n",
    "print(pd.isnull(req_data).any())\n",
    "print(pd.isnull(req_data['Scenario']).any())\n",
    "req_data = req_data[np.isfinite(data['Scenario'])]\n",
    "print(pd.isnull(req_data['Scenario']).any())\n",
    "req_data['damages'].fillna(0,inplace=True)\n",
    "req_data['damages_word'].fillna(0,inplace=True)\n",
    "req_data['mm_perc'].fillna(1,inplace=True)\n",
    "req_data['perc_calc'].fillna(0,inplace=True)\n",
    "#Dropping the last two rows which has null values\n",
    "#data[pd.isnull(data['Path'])]\n",
    "#data['Path']=data.Path.dropna(inplace= True)\n",
    "#data[pd.isnull(data['Path'])]\n",
    "print(pd.isnull(req_data).any())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Changing data types of columns\n",
    "req_data['End Date'] = pd.to_datetime(data['End Date'])\n",
    "req_data['Start Date'] = pd.to_datetime(data['Start Date'])\n",
    "req_data['Scenario']= req_data.Scenario.astype(int)\n",
    "req_data['Liability']= req_data.Liability.astype(int)\n",
    "req_data.dtypes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Getting the id of the column\n",
    "data.columns.get_loc(\"Liability\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cleaning Damages and perc_calc column\n",
    "print(req_data.isnull().any())\n",
    "req_data['damages'] = req_data['damages'].str.replace(',', '')\n",
    "req_data['perc_calc'] = req_data['perc_calc'].str.replace('$', '')\n",
    "req_data['perc_calc'] = req_data['perc_calc'].str.replace(',', '')\n",
    "req_data['perc_calc'] = req_data['perc_calc'].str.replace('-', '')\n",
    "req_data['perc_calc'] = req_data['perc_calc'].str.replace(\"  \", '')\n",
    "req_data['mm_perc'] = req_data['mm_perc'].str.replace(\"$\", '')\n",
    "req_data['mm_perc'] = req_data['mm_perc'].str.replace(\",\", '')\n",
    "req_data['mm_perc'] = req_data['mm_perc'].str.replace(\"  \", '')\n",
    "#req_data.damages=pd.to_numeric(req_data['damages'].str.replace(',', ''))\n",
    "#req_data.perc_calc=pd.to_numeric(req_data.perc_calc)\n",
    "#print(req_data.isnull().any())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "req_data.damages=pd.to_numeric(req_data['damages'])\n",
    "req_data.perc_calc=pd.to_numeric(req_data.perc_calc)\n",
    "req_data['damages'].fillna(0,inplace=True)  \n",
    "req_data['mm_perc'].fillna(1,inplace=True)\n",
    "req_data['perc_calc'].fillna(0,inplace=True)\n",
    "#print(req_data.damages)\n",
    "print(req_data.isnull().any())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(req_data[pd.isnull(req_data['Dunn_negligent'])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#EDA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "req_data['winrate_percentage']=req_data.Liability\n",
    "req_data['damages_mean']=req_data.damages+req_data.perc_calc\n",
    "req_data['damages_median']=req_data.damages\n",
    "req_data['damages_sd']=req_data.damages\n",
    "\n",
    "winrate_damages_expected=req_data.groupby('Scenario').aggregate(\n",
    "    {'winrate_percentage': np.mean, 'damages_mean': np.mean,'damages_median':np.median,'damages_sd':np.std})\n",
    "\n",
    "\n",
    "winrate_damages_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#req_data['winrate_percentage']=np.mean(req_data.Juror_Response)\n",
    "#print(req_data)\n",
    "req_data['mm_perc'].fillna(1,inplace=True)\n",
    "req_data['damages_mean1']=req_data.damages*pd.to_numeric(req_data.mm_perc)\n",
    "req_data['damages_median1']=req_data.damages\n",
    "req_data['damages_sd1']=req_data.damages\n",
    "#print(req_data.mm_perc)\n",
    "\n",
    "winrate_damages_plaintiffwin=req_data.loc[(req_data['Dunn_negligent']=='No') & (req_data['Liability']==1)].groupby('Scenario').aggregate({'damages_mean1': np.mean,'damages_median1':np.median,'damages_sd1':np.std})\n",
    "\n",
    "\n",
    "winrate_damages_plaintiffwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.factorplot(x='Scenario', y='damages', kind='box',data=req_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Scenario,data.Liability).plot(kind='bar')\n",
    "plt.title('Purchase Frequency for Job Title')\n",
    "plt.xlabel('Scenario')\n",
    "plt.ylabel('Liability')\n",
    "plt.savefig('Juror Response per each Scenario')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = req_data['Scenario']\n",
    "b = req_data['Liability']\n",
    "pd.crosstab(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### New data set ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pruthwiraj\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>ResponseType</th>\n",
       "      <th>IP Address</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>RecipientLastName</th>\n",
       "      <th>...</th>\n",
       "      <th>Was_snowboard_sold_McNeil_defective_58</th>\n",
       "      <th>Is_substantial_factor_McNeil_injuries_58</th>\n",
       "      <th>Economic_damages_McNeil_suffer_58</th>\n",
       "      <th>Economic_Damages_In_Word_58</th>\n",
       "      <th>Non_economic_damages_McNeil_suffered_58</th>\n",
       "      <th>Non_Economic_Damages_In_Word_58</th>\n",
       "      <th>Please explain why you arrived at your decision? (50 character minimum)</th>\n",
       "      <th>Did the fact that X5 added core inserts to the later Carve 3000 model, affect your view as to whether the original Carve 3000 was defective?</th>\n",
       "      <th>Were you able to ignore the  fact that X5 added core inserts to the later Carve 3000 model when deciding whether the original Carve 3000 was defective?</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00004\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00005\u0000</td>\n",
       "      <td>\u00000\u0000</td>\n",
       "      <td>\u00007\u00006\u0000.\u00008\u00004\u0000.\u00002\u00005\u00000\u0000.\u00001\u00004\u00003\u0000</td>\n",
       "      <td>\u00001\u00000\u00000\u0000</td>\n",
       "      <td>\u00003\u00004\u0000</td>\n",
       "      <td>\u00001\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00005\u0000</td>\n",
       "      <td>\u0000R\u0000_\u00002\u0000V\u0000e\u0000D\u0000w\u00006\u0000k\u0000P\u0000p\u0000O\u00007\u0000N\u0000X\u0000v\u0000z\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>...</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00005\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00006\u0000</td>\n",
       "      <td>\u00000\u0000</td>\n",
       "      <td>\u00001\u00000\u00007\u0000.\u00001\u00004\u00000\u0000.\u00001\u00009\u00001\u0000.\u00001\u00007\u00006\u0000</td>\n",
       "      <td>\u00001\u00000\u00000\u0000</td>\n",
       "      <td>\u00004\u00002\u0000</td>\n",
       "      <td>\u00001\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00006\u0000</td>\n",
       "      <td>\u0000R\u0000_\u00001\u0000e\u0000J\u0000q\u00001\u0000K\u0000w\u0000X\u0000T\u0000Y\u0000y\u0000a\u0000e\u0000w\u0000m\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>...</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00007\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00008\u0000</td>\n",
       "      <td>\u00000\u0000</td>\n",
       "      <td>\u00001\u00003\u00008\u0000.\u00002\u00000\u00007\u0000.\u00001\u00006\u00008\u0000.\u00001\u00004\u00008\u0000</td>\n",
       "      <td>\u00001\u00000\u00000\u0000</td>\n",
       "      <td>\u00006\u00000\u0000</td>\n",
       "      <td>\u00001\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00008\u0000</td>\n",
       "      <td>\u0000R\u0000_\u00002\u0000q\u0000l\u0000Q\u0000Q\u0000Y\u00004\u0000F\u0000U\u0000r\u0000K\u0000Y\u0000e\u0000y\u0000z\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>...</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u00006\u0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00007\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00008\u0000</td>\n",
       "      <td>\u00000\u0000</td>\n",
       "      <td>\u00007\u00002\u0000.\u00001\u00009\u00008\u0000.\u00007\u00004\u0000.\u00001\u00003\u00005\u0000</td>\n",
       "      <td>\u00001\u00000\u00000\u0000</td>\n",
       "      <td>\u00006\u00009\u0000</td>\n",
       "      <td>\u00001\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00008\u0000</td>\n",
       "      <td>\u0000R\u0000_\u00001\u0000l\u0000m\u0000Z\u0000b\u0000A\u0000x\u0000g\u0000O\u00000\u0000A\u0000P\u0000U\u00005\u0000T\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>...</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00004\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00009\u0000</td>\n",
       "      <td>\u00000\u0000</td>\n",
       "      <td>\u00001\u00000\u00007\u0000.\u00007\u00007\u0000.\u00002\u00000\u00009\u0000.\u00004\u00002\u0000</td>\n",
       "      <td>\u00001\u00000\u00000\u0000</td>\n",
       "      <td>\u00002\u00005\u00005\u0000</td>\n",
       "      <td>\u00001\u0000</td>\n",
       "      <td>\u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00009\u0000</td>\n",
       "      <td>\u0000R\u0000_\u00001\u0000n\u0000O\u0000b\u0000S\u0000X\u0000p\u0000L\u00005\u0000d\u00000\u0000w\u0000f\u0000Q\u0000S\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>...</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>\u00007\u0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   StartDate                    EndDate ResponseType  \\\n",
       "0  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00004\u0000  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00005\u0000          \u00000\u0000   \n",
       "1  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00005\u0000  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00006\u0000          \u00000\u0000   \n",
       "2  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00007\u0000  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00008\u0000          \u00000\u0000   \n",
       "3  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00007\u0000  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00008\u0000          \u00000\u0000   \n",
       "4  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00004\u0000  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00009\u0000          \u00000\u0000   \n",
       "\n",
       "                        IP Address Progress Duration Finished  \\\n",
       "0      \u00007\u00006\u0000.\u00008\u00004\u0000.\u00002\u00005\u00000\u0000.\u00001\u00004\u00003\u0000  \u00001\u00000\u00000\u0000    \u00003\u00004\u0000      \u00001\u0000   \n",
       "1  \u00001\u00000\u00007\u0000.\u00001\u00004\u00000\u0000.\u00001\u00009\u00001\u0000.\u00001\u00007\u00006\u0000  \u00001\u00000\u00000\u0000    \u00004\u00002\u0000      \u00001\u0000   \n",
       "2  \u00001\u00003\u00008\u0000.\u00002\u00000\u00007\u0000.\u00001\u00006\u00008\u0000.\u00001\u00004\u00008\u0000  \u00001\u00000\u00000\u0000    \u00006\u00000\u0000      \u00001\u0000   \n",
       "3      \u00007\u00002\u0000.\u00001\u00009\u00008\u0000.\u00007\u00004\u0000.\u00001\u00003\u00005\u0000  \u00001\u00000\u00000\u0000    \u00006\u00009\u0000      \u00001\u0000   \n",
       "4      \u00001\u00000\u00007\u0000.\u00007\u00007\u0000.\u00002\u00000\u00009\u0000.\u00004\u00002\u0000  \u00001\u00000\u00000\u0000  \u00002\u00005\u00005\u0000      \u00001\u0000   \n",
       "\n",
       "                RecordedDate                           ResponseID  \\\n",
       "0  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00005\u0000  \u0000R\u0000_\u00002\u0000V\u0000e\u0000D\u0000w\u00006\u0000k\u0000P\u0000p\u0000O\u00007\u0000N\u0000X\u0000v\u0000z\u0000   \n",
       "1  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00006\u0000  \u0000R\u0000_\u00001\u0000e\u0000J\u0000q\u00001\u0000K\u0000w\u0000X\u0000T\u0000Y\u0000y\u0000a\u0000e\u0000w\u0000m\u0000   \n",
       "2  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00008\u0000  \u0000R\u0000_\u00002\u0000q\u0000l\u0000Q\u0000Q\u0000Y\u00004\u0000F\u0000U\u0000r\u0000K\u0000Y\u0000e\u0000y\u0000z\u0000   \n",
       "3  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00008\u0000  \u0000R\u0000_\u00001\u0000l\u0000m\u0000Z\u0000b\u0000A\u0000x\u0000g\u0000O\u00000\u0000A\u0000P\u0000U\u00005\u0000T\u0000   \n",
       "4  \u00004\u0000/\u00006\u0000/\u00001\u00008\u0000 \u00001\u00003\u0000:\u00001\u00009\u0000  \u0000R\u0000_\u00001\u0000n\u0000O\u0000b\u0000S\u0000X\u0000p\u0000L\u00005\u0000d\u00000\u0000w\u0000f\u0000Q\u0000S\u0000   \n",
       "\n",
       "  RecipientLastName ...  Was_snowboard_sold_McNeil_defective_58  \\\n",
       "0                 \u0000 ...                                       \u0000   \n",
       "1                 \u0000 ...                                       \u0000   \n",
       "2                 \u0000 ...                                       \u0000   \n",
       "3                 \u0000 ...                                       \u0000   \n",
       "4                 \u0000 ...                                       \u0000   \n",
       "\n",
       "  Is_substantial_factor_McNeil_injuries_58 Economic_damages_McNeil_suffer_58  \\\n",
       "0                                        \u0000                                 \u0000   \n",
       "1                                        \u0000                                 \u0000   \n",
       "2                                        \u0000                                 \u0000   \n",
       "3                                        \u0000                                 \u0000   \n",
       "4                                        \u0000                                 \u0000   \n",
       "\n",
       "  Economic_Damages_In_Word_58 Non_economic_damages_McNeil_suffered_58  \\\n",
       "0                           \u0000                                       \u0000   \n",
       "1                           \u0000                                       \u0000   \n",
       "2                           \u0000                                       \u0000   \n",
       "3                           \u0000                                       \u0000   \n",
       "4                           \u0000                                       \u0000   \n",
       "\n",
       "  Non_Economic_Damages_In_Word_58  \\\n",
       "0                               \u0000   \n",
       "1                               \u0000   \n",
       "2                               \u0000   \n",
       "3                               \u0000   \n",
       "4                               \u0000   \n",
       "\n",
       "  Please explain why you arrived at your decision? (50 character minimum)  \\\n",
       "0                                                  \u0000                        \n",
       "1                                                  \u0000                        \n",
       "2                                                  \u0000                        \n",
       "3                                                  \u0000                        \n",
       "4                                                  \u0000                        \n",
       "\n",
       "  Did the fact that X5 added core inserts to the later Carve 3000 model, affect your view as to whether the original Carve 3000 was defective?  \\\n",
       "0                                                  \u0000                                                                                             \n",
       "1                                                  \u0000                                                                                             \n",
       "2                                                  \u0000                                                                                             \n",
       "3                                                  \u0000                                                                                             \n",
       "4                                                  \u0000                                                                                             \n",
       "\n",
       "  Were you able to ignore the  fact that X5 added core inserts to the later Carve 3000 model when deciding whether the original Carve 3000 was defective?  \\\n",
       "0                                                  \u0000                                                                                                        \n",
       "1                                                  \u0000                                                                                                        \n",
       "2                                                  \u0000                                                                                                        \n",
       "3                                                  \u0000                                                                                                        \n",
       "4                                                  \u0000                                                                                                        \n",
       "\n",
       "  Path  \n",
       "0    \u0000  \n",
       "1    \u0000  \n",
       "2  \u00006\u0000  \n",
       "3    \u0000  \n",
       "4  \u00007\u0000  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('Low_Anchor.tsv', sep='\\t+',skiprows=[0,2, 4]+list(range(1,1614,2)) + [1614], names = ['StartDate', 'EndDate',\n",
    "       'ResponseType', \n",
    "       'IP Address', \n",
    "       'Progress', \n",
    "       'Duration',\n",
    "       'Finished',\n",
    "       'RecordedDate',\n",
    "       'ResponseID', \n",
    "       'RecipientLastName','RecipientFirstName','RecipientEmail',\n",
    "       'ExternalDataReference','LocationLatitude', 'LocationLongitude',\n",
    "       'DistributionChannel', 'UserLanguage', 'Participation_in_this_project.',\n",
    "       'Browser Meta Info - Browser',\n",
    "       'Browser Meta Info - Version',\n",
    "       'Browser Meta Info - Operating System',\n",
    "       'Browser Meta Info - Resolution',\n",
    "       'What number did you hear?',\n",
    "       'What word did you see?',\n",
    "       'What is your sex?',\n",
    "       'How old are you?',\n",
    "       'Which of the following best describes your ethnicity?',\n",
    "       'Are you Spanish/Hispanic/Latino',\n",
    "       'What is the highest degree or level of school you have completed?',\n",
    "       'This is an attention check.  Select 200.',\n",
    "       'Which of the following best describes your total household income?',\n",
    "       'Where would you place yourself on this scale?',\n",
    "       'What is your zip code?',\n",
    "       'Timing - First Click','Timing - Last Click','Timing - Page Submit', 'Timing - Click Count',\n",
    "       'Timing - First Click.1', 'Timing - Last Click.1', 'Timing - Page Submit.1',\n",
    "       'Timing - Click Count.1', 'Timing - First Click.2','Timing - Last Click.2',\n",
    "       'Timing - Page Submit.2','Timing - Click Count.2','Timing - First Click.3','Timing - Last Click.3',\n",
    "       'Timing - Page Submit.3','Timing - Click Count.3','Timing - First Click.4', 'Timing - Last Click.4',\n",
    "       'Timing - Page Submit.4','Timing - Click Count.4', 'Timing - First Click.5', 'Timing - Last Click.5',\n",
    "       'Timing - Page Submit.5','Timing - Click Count.5', 'Timing - First Click.6', 'Timing - Last Click.6',\n",
    "       'Timing - Page Submit.6',  'Timing - Click Count.6', 'Timing - First Click.7','Timing - Last Click.7',\n",
    "       'Timing - Page Submit.7',  'Timing - Click Count.7',\n",
    "       'Identify the statement that correctly describes the facts of this case. (This is the attention check)',\n",
    "       'Was_snowboard_sold_McNeil_defective_14', ## using this\n",
    "       \"Is_substantial_factor_McNeil_injuries_14\",\n",
    "       'Non_economic_damages_McNeil_suffered_14',\n",
    "       'Damages_words_14',\n",
    "       'Was_McNeil_negligent',\n",
    "       'McNeil_negligence_substantial_factor_for_injuries',\n",
    "       'Percentage_of_responsibility_X5',\n",
    "       'Percentage_of_responsibility_McNeil',\n",
    "       'Was_snowboard_sold_McNeil_defective_58',\n",
    "       \"Is_substantial_factor_McNeil_injuries_58\",\n",
    "       'Economic_damages_McNeil_suffer_58',\n",
    "       'Economic_Damages_In_Word_58',\n",
    "       'Non_economic_damages_McNeil_suffered_58',\n",
    "       'Non_Economic_Damages_In_Word_58',\n",
    "       'Please explain why you arrived at your decision? (50 character minimum)',\n",
    "       'Did the fact that X5 added core inserts to the later Carve 3000 model, affect your view as to whether the original Carve 3000 was defective?',\n",
    "       'Were you able to ignore the  fact that X5 added core inserts to the later Carve 3000 model when deciding whether the original Carve 3000 was defective?',\n",
    "       'Path'])\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## replacing hexadecimal value of damages'/x00' to ''\n",
    "for i in range(len(df)):\n",
    "    df['Was_snowboard_sold_McNeil_defective_14'].values[i] = df['Was_snowboard_sold_McNeil_defective_14'].values[i].replace('\\x00','')\n",
    "    df['Is_substantial_factor_McNeil_injuries_14'].values[i] = df['Is_substantial_factor_McNeil_injuries_14'].values[i].replace('\\x00','')\n",
    "    df['Non_economic_damages_McNeil_suffered_14'].values[i] = df['Non_economic_damages_McNeil_suffered_14'].values[i].replace('\\x00','')\n",
    "    df['Damages_words_14'].values[i] = df['Damages_words_14'].values[i].replace('\\x00','')\n",
    "    df['Was_McNeil_negligent'].values[i] = df['Was_McNeil_negligent'].values[i].replace('\\x00','') ;\n",
    "    df['McNeil_negligence_substantial_factor_for_injuries'].values[i] = df['McNeil_negligence_substantial_factor_for_injuries'].values[i].replace('\\x00','') ;\n",
    "    df['Percentage_of_responsibility_X5'].values[i] = df['Percentage_of_responsibility_X5'].values[i].replace('\\x00','') ;\n",
    "    df['Percentage_of_responsibility_McNeil'].values[i] = df['Percentage_of_responsibility_McNeil'].values[i].replace('\\x00','') ;\n",
    "    df['Was_snowboard_sold_McNeil_defective_58'].values[i] = df['Was_snowboard_sold_McNeil_defective_58'].values[i].replace('\\x00','') ;\n",
    "    df['Is_substantial_factor_McNeil_injuries_58'].values[i] = df['Is_substantial_factor_McNeil_injuries_58'].values[i].replace('\\x00','') ;\n",
    "    df['Economic_damages_McNeil_suffer_58'].values[i] = df['Economic_damages_McNeil_suffer_58'].values[i].replace('\\x00','') ;\n",
    "    df['Economic_Damages_In_Word_58'].values[i] = df['Economic_Damages_In_Word_58'].values[i].replace('\\x00','') ;\n",
    "    df['Non_economic_damages_McNeil_suffered_58'].values[i] = df['Non_economic_damages_McNeil_suffered_58'].values[i].replace('\\x00','') ;\n",
    "    df['Non_Economic_Damages_In_Word_58'].values[i] = df['Non_Economic_Damages_In_Word_58'].values[i].replace('\\x00','') ;\n",
    "    df['Path'].values[i] = df['Path'].values[i].replace('\\x00','') ;  \n",
    "    #df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].values[i] =  df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].values[i].replace('\\x00','') ;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing NAN value to 0 for path to change the datatype to int\n",
    "# df['Path'].apply(lambda x: x.strip()).replace('', -1, inplace = True);\n",
    "# df['non_economic_damages_suffered'].fillna(0 ,inplace = True)\n",
    "# df['non_economic_damages_suffered'].fillna(0 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].fillna(0 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Handling for Path Variable. The data type is string and we want it to be interger. There are some null\n",
    "## values so chanding the datatype to float..\n",
    "df.Path = pd.to_numeric(df.Path) \n",
    "#After converting to float the null string updated with NAN so updating those value with 0.\n",
    "df['Path'].fillna(0,inplace = True)\n",
    "# After that coverting Dtype to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Changing Data type\n",
    "df.StartDate = pd.to_datetime(df.StartDate)\n",
    "df.EndDate   = pd.to_datetime(df.EndDate) \n",
    "#df.Was_snowboard_sold_McNeil_defective_14   = pd.to_numeric(df.Was_snowboard_sold_McNeil_defective_14)\n",
    "df.Is_substantial_factor_McNeil_injuries_14 = pd.to_numeric(df.Is_substantial_factor_McNeil_injuries_14)\n",
    "df.Non_economic_damages_McNeil_suffered_14  = pd.to_numeric(df.Non_economic_damages_McNeil_suffered_14)\n",
    "df.Was_McNeil_negligent                     = pd.to_numeric(df.Was_McNeil_negligent)\n",
    "df.McNeil_negligence_substantial_factor_for_injuries= pd.to_numeric(df.McNeil_negligence_substantial_factor_for_injuries)\n",
    "df.Percentage_of_responsibility_X5          = pd.to_numeric(df.Percentage_of_responsibility_X5)\n",
    "df.Percentage_of_responsibility_McNeil      = pd.to_numeric(df.Percentage_of_responsibility_McNeil)\n",
    "df.Was_snowboard_sold_McNeil_defective_58   = pd.to_numeric(df.Was_snowboard_sold_McNeil_defective_58)\n",
    "df.Is_substantial_factor_McNeil_injuries_58 = pd.to_numeric(df.Is_substantial_factor_McNeil_injuries_58)\n",
    "df.Economic_damages_McNeil_suffer_58        = pd.to_numeric(df.Economic_damages_McNeil_suffer_58)\n",
    "df.Non_economic_damages_McNeil_suffered_58  = pd.to_numeric(df.Non_economic_damages_McNeil_suffered_58)\n",
    "# Handling for Path\n",
    "df.Path = pd.to_numeric(df.Path) \n",
    "df['Path'].fillna(0,inplace = True)\n",
    "df.Path =  df.Path.astype(int)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 4: yes (changed to 1), 6: No (changed to 0)\n",
    "df['Was_snowboard_sold_McNeil_defective_14'].replace(['4.0', '6.0'], ['Yes','No'], inplace = True)\n",
    "#df['Is_substantial_factor_McNeil_injuries_14'].replace([5.0, 6.0], [1,0], inplace = True)\n",
    "\n",
    "## need computation for Non_economic_damages_McNeil_suffered_14. so deal with NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "pd.crosstab(df.Path, df.Was_snowboard_sold_McNeil_defective_14).plot(kind = 'bar')\n",
    "#pd.crosstab(df.Path, df.Was_snowboard_sold_McNeil_defective_58).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.Economic_damages_McNeil_suffer_58        = pd.to_numeric(df.Economic_damages_McNeil_suffer_58)\n",
    "df.Non_economic_damages_McNeil_suffered_58  = pd.to_numeric(df.Non_economic_damages_McNeil_suffered_58)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "newdf58 = df[(df.Path == 5) | (df.Path == 6) | (df.Path == 7)| (df.Path == 8)]\n",
    "newdf14 = df[(df.Path == 1) | (df.Path == 2) | (df.Path == 3)| (df.Path == 4)]\n",
    "newdf14 = newdf14[np.isfinite(newdf14['Non_economic_damages_McNeil_suffered_14'])]\n",
    "newdf14[['Non_economic_damages_McNeil_suffered_14', 'Path']]\n",
    "#newdf14.plot( x = 'Path', y = 'Non_economic_damages_McNeil_suffered_14', kind = 'bar')\n",
    "sns.factorplot( x = 'Path', y = 'Non_economic_damages_McNeil_suffered_14', kind = 'box', data = newdf14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Economic_damages_McNeil_suffer_58.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x= 'Path', y = 'Non_economic_damages_McNeil_suffered_14', kind = 'box', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf= pd.DataFrame(df.Was_snowboard_sold_McNeil_defective_14,df.Was_snowboard_sold_McNeil_defective_58,Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['Was_snowboard_sold_McNeil_defective_14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Path,df.Was_snowboard_sold_McNeil_defective_14)\n",
    "#pd.crosstab(df.Path,df.Was_snowboard_sold_McNeil_defective_58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req_data['winrate_percentage']=req_data.Liability\n",
    "df_winrate = df.loc[(df['Was_snowboard_sold_McNeil_defective_14']=='Yes')].groupby('Path').aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_table = df.pivot_table(values=['Was_snowboard_sold_McNeil_defective_14'], index=[\"Was_snowboard_sold_McNeil_defective_14\",\"Is_substantial_factor_McNeil_injuries_14\"],aggfunc=np.average)\n",
    "print(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Null Checking\n",
    "any(df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jury_data1.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Test code to convert currency in word to integer value \n",
    "#for i in df['']\n",
    "newdf = df.filter(['What non-economic damages did Connor McNeil suffer? (in dollars)','Please write your answer to the preceding damages question in words (quality check)..2'], axis=1)\n",
    "newdf['Newcol'] = 0\n",
    "newdf.columns = ['a', 'b', 'c']\n",
    "newdf.head()\n",
    "\n",
    "from word2number import w2n\n",
    "a = \"2 hundred thousand dollars\"\n",
    "lst = list(range(1,1000))\n",
    "t = a.split\n",
    "print(t)\n",
    "try:\n",
    "    print(w2n.word_to_num(a))\n",
    "except:\n",
    "    print(\"error occur\")\n",
    "df.columns\n",
    "\n",
    "for index,row in newdf.iterrows():\n",
    "    word = row['b']\n",
    "    print(row['b'])\n",
    "    try:\n",
    "        row['c'] = w2n.word_to_num(word)\n",
    "    except:\n",
    "        print(\"error occur\", word)\n",
    "newdf['c'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
