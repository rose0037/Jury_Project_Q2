{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read jury data \n",
    "jury_data1 = pd.read_csv('jury_data.csv', encoding= 'ISO-8859-1',skiprows=[0,2])\n",
    "jury_data1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To describe columns\n",
    "jury_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jury_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To check data type of each columns.\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Changing Data type\n",
    "data['End Date'] = pd.to_datetime(data['End Date'])\n",
    "data['Start Date'] = pd.to_datetime(data['Start Date'])\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('jury2.tsv', sep='\\t+')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('jury2.tsv', sep='\\t+',skiprows=[0,2, 4]+list(range(1,1614,2)) + [1614], names = ['StartDate', 'EndDate',\n",
    "       'ResponseType', \n",
    "       'IP Address', \n",
    "       'Progress', \n",
    "       'Duration',\n",
    "       'Finished',\n",
    "       'RecordedDate',\n",
    "       'ResponseID', \n",
    "       'RecipientLastName','RecipientFirstName','RecipientEmail',\n",
    "       'ExternalDataReference','LocationLatitude', 'LocationLongitude',\n",
    "       'DistributionChannel', 'UserLanguage', 'Participation_in_this_project.',\n",
    "       'Browser Meta Info - Browser',\n",
    "       'Browser Meta Info - Version',\n",
    "       'Browser Meta Info - Operating System',\n",
    "       'Browser Meta Info - Resolution',\n",
    "       'What number did you hear?',\n",
    "       'What word did you see?',\n",
    "       'What is your sex?',\n",
    "       'How old are you?',\n",
    "       'Which of the following best describes your ethnicity?',\n",
    "       'Are you Spanish/Hispanic/Latino',\n",
    "       'What is the highest degree or level of school you have completed?',\n",
    "       'This is an attention check.  Select 200.',\n",
    "       'Which of the following best describes your total household income?',\n",
    "       'Where would you place yourself on this scale?',\n",
    "       'What is your zip code?',\n",
    "       'Timing - First Click','Timing - Last Click','Timing - Page Submit', 'Timing - Click Count',\n",
    "       'Timing - First Click.1', 'Timing - Last Click.1', 'Timing - Page Submit.1',\n",
    "       'Timing - Click Count.1', 'Timing - First Click.2','Timing - Last Click.2',\n",
    "       'Timing - Page Submit.2','Timing - Click Count.2','Timing - First Click.3','Timing - Last Click.3',\n",
    "       'Timing - Page Submit.3','Timing - Click Count.3','Timing - First Click.4', 'Timing - Last Click.4',\n",
    "       'Timing - Page Submit.4','Timing - Click Count.4', 'Timing - First Click.5', 'Timing - Last Click.5',\n",
    "       'Timing - Page Submit.5','Timing - Click Count.5', 'Timing - First Click.6', 'Timing - Last Click.6',\n",
    "       'Timing - Page Submit.6',  'Timing - Click Count.6', 'Timing - First Click.7','Timing - Last Click.7',\n",
    "       'Timing - Page Submit.7',  'Timing - Click Count.7',\n",
    "       'Identify the statement that correctly describes the facts of this case. (This is the attention check)',\n",
    "       'Was_snowboard_sold_McNeil_defective_14', ## using this\n",
    "       \"Is_substantial_factor_McNeil_injuries_14\",\n",
    "       'Non_economic_damages_McNeil_suffered_14',\n",
    "       'Damages_words_14',\n",
    "       'Was_McNeil_negligent',\n",
    "       'McNeil_negligence_substantial_factor_for_injuries',\n",
    "       'Percentage_of_responsibility_X5',\n",
    "       'Percentage_of_responsibility_McNeil',\n",
    "       'Was_snowboard_sold_McNeil_defective_58',\n",
    "       \"Is_substantial_factor_McNeil_injuries_58\",\n",
    "       'Economic_damages_McNeil_suffer_58',\n",
    "       'Economic_Damages_In_Word_58',\n",
    "       'Non_economic_damages_McNeil_suffered_58',\n",
    "       'Non_Economic_Damages_In_Word_58',\n",
    "       'Please explain why you arrived at your decision? (50 character minimum)',\n",
    "       'Did the fact that X5 added core inserts to the later Carve 3000 model, affect your view as to whether the original Carve 3000 was defective?',\n",
    "       'Were you able to ignore the  fact that X5 added core inserts to the later Carve 3000 model when deciding whether the original Carve 3000 was defective?',\n",
    "       'Path'])\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## replacing hexadecimal value of damages'/x00' to ''\n",
    "for i in range(len(df)):\n",
    "    df['Was_snowboard_sold_McNeil_defective_14'].values[i] = df['Was_snowboard_sold_McNeil_defective_14'].values[i].replace('\\x00','')\n",
    "    df['Is_substantial_factor_McNeil_injuries_14'].values[i] = df['Is_substantial_factor_McNeil_injuries_14'].values[i].replace('\\x00','')\n",
    "    df['Non_economic_damages_McNeil_suffered_14'].values[i] = df['Non_economic_damages_McNeil_suffered_14'].values[i].replace('\\x00','')\n",
    "    df['Damages_words_14'].values[i] = df['Damages_words_14'].values[i].replace('\\x00','')\n",
    "    df['Was_McNeil_negligent'].values[i] = df['Was_McNeil_negligent'].values[i].replace('\\x00','') ;\n",
    "    df['McNeil_negligence_substantial_factor_for_injuries'].values[i] = df['McNeil_negligence_substantial_factor_for_injuries'].values[i].replace('\\x00','') ;\n",
    "    df['Percentage_of_responsibility_X5'].values[i] = df['Percentage_of_responsibility_X5'].values[i].replace('\\x00','') ;\n",
    "    df['Percentage_of_responsibility_McNeil'].values[i] = df['Percentage_of_responsibility_McNeil'].values[i].replace('\\x00','') ;\n",
    "    df['Was_snowboard_sold_McNeil_defective_58'].values[i] = df['Was_snowboard_sold_McNeil_defective_58'].values[i].replace('\\x00','') ;\n",
    "    df['Is_substantial_factor_McNeil_injuries_58'].values[i] = df['Is_substantial_factor_McNeil_injuries_58'].values[i].replace('\\x00','') ;\n",
    "    df['Economic_damages_McNeil_suffer_58'].values[i] = df['Economic_damages_McNeil_suffer_58'].values[i].replace('\\x00','') ;\n",
    "    df['Economic_Damages_In_Word_58'].values[i] = df['Economic_Damages_In_Word_58'].values[i].replace('\\x00','') ;\n",
    "    df['Non_economic_damages_McNeil_suffered_58'].values[i] = df['Non_economic_damages_McNeil_suffered_58'].values[i].replace('\\x00','') ;\n",
    "    df['Non_Economic_Damages_In_Word_58'].values[i] = df['Non_Economic_Damages_In_Word_58'].values[i].replace('\\x00','') ;\n",
    "    df['Path'].values[i] = df['Path'].values[i].replace('\\x00','') ;  \n",
    "    #df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].values[i] =  df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].values[i].replace('\\x00','') ;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing NAN value to 0 for path to change the datatype to int\n",
    "# df['Path'].apply(lambda x: x.strip()).replace('', -1, inplace = True);\n",
    "# df['non_economic_damages_suffered'].fillna(0 ,inplace = True)\n",
    "# df['non_economic_damages_suffered'].fillna(0 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].fillna(0 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Handling for Path Variable. The data type is string and we want it to be interger. There are some null\n",
    "## values so chanding the datatype to float..\n",
    "df.Path = pd.to_numeric(df.Path) \n",
    "#After converting to float the null string updated with NAN so updating those value with 0.\n",
    "df['Path'].fillna(0,inplace = True)\n",
    "# After that coverting Dtype to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Changing Data type\n",
    "df.StartDate = pd.to_datetime(df.StartDate)\n",
    "df.EndDate   = pd.to_datetime(df.EndDate) \n",
    "#df.Was_snowboard_sold_McNeil_defective_14   = pd.to_numeric(df.Was_snowboard_sold_McNeil_defective_14)\n",
    "df.Is_substantial_factor_McNeil_injuries_14 = pd.to_numeric(df.Is_substantial_factor_McNeil_injuries_14)\n",
    "df.Non_economic_damages_McNeil_suffered_14  = pd.to_numeric(df.Non_economic_damages_McNeil_suffered_14)\n",
    "df.Was_McNeil_negligent                     = pd.to_numeric(df.Was_McNeil_negligent)\n",
    "df.McNeil_negligence_substantial_factor_for_injuries= pd.to_numeric(df.McNeil_negligence_substantial_factor_for_injuries)\n",
    "df.Percentage_of_responsibility_X5          = pd.to_numeric(df.Percentage_of_responsibility_X5)\n",
    "df.Percentage_of_responsibility_McNeil      = pd.to_numeric(df.Percentage_of_responsibility_McNeil)\n",
    "df.Was_snowboard_sold_McNeil_defective_58   = pd.to_numeric(df.Was_snowboard_sold_McNeil_defective_58)\n",
    "df.Is_substantial_factor_McNeil_injuries_58 = pd.to_numeric(df.Is_substantial_factor_McNeil_injuries_58)\n",
    "df.Economic_damages_McNeil_suffer_58        = pd.to_numeric(df.Economic_damages_McNeil_suffer_58)\n",
    "df.Non_economic_damages_McNeil_suffered_58  = pd.to_numeric(df.Non_economic_damages_McNeil_suffered_58)\n",
    "# Handling for Path\n",
    "df.Path = pd.to_numeric(df.Path) \n",
    "df['Path'].fillna(0,inplace = True)\n",
    "df.Path =  df.Path.astype(int)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 4: yes (changed to 1), 6: No (changed to 0)\n",
    "df['Was_snowboard_sold_McNeil_defective_14'].replace(['4.0', '6.0'], ['Yes','No'], inplace = True)\n",
    "#df['Is_substantial_factor_McNeil_injuries_14'].replace([5.0, 6.0], [1,0], inplace = True)\n",
    "\n",
    "## need computation for Non_economic_damages_McNeil_suffered_14. so deal with NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "pd.crosstab(df.Path, df.Was_snowboard_sold_McNeil_defective_14).plot(kind = 'bar')\n",
    "#pd.crosstab(df.Path, df.Was_snowboard_sold_McNeil_defective_58).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.Economic_damages_McNeil_suffer_58        = pd.to_numeric(df.Economic_damages_McNeil_suffer_58)\n",
    "df.Non_economic_damages_McNeil_suffered_58  = pd.to_numeric(df.Non_economic_damages_McNeil_suffered_58)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "newdf58 = df[(df.Path == 5) | (df.Path == 6) | (df.Path == 7)| (df.Path == 8)]\n",
    "newdf14 = df[(df.Path == 1) | (df.Path == 2) | (df.Path == 3)| (df.Path == 4)]\n",
    "newdf14 = newdf14[np.isfinite(newdf14['Non_economic_damages_McNeil_suffered_14'])]\n",
    "newdf14[['Non_economic_damages_McNeil_suffered_14', 'Path']]\n",
    "#newdf14.plot( x = 'Path', y = 'Non_economic_damages_McNeil_suffered_14', kind = 'bar')\n",
    "sns.factorplot( x = 'Path', y = 'Non_economic_damages_McNeil_suffered_14', kind = 'box', data = newdf14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Economic_damages_McNeil_suffer_58.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x= 'Path', y = 'Non_economic_damages_McNeil_suffered_14', kind = 'box', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Was_snowboard_sold_McNeil_defective_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf= pd.DataFrame(df.Was_snowboard_sold_McNeil_defective_14,df.Was_snowboard_sold_McNeil_defective_58,Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['Was_snowboard_sold_McNeil_defective_14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Path,df.Was_snowboard_sold_McNeil_defective_14)\n",
    "#pd.crosstab(df.Path,df.Was_snowboard_sold_McNeil_defective_58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req_data['winrate_percentage']=req_data.Liability\n",
    "df_winrate = df.loc[(df['Was_snowboard_sold_McNeil_defective_14']=='Yes')].groupby('Path').aggregate(\n",
    "    {'damages_mean1': np.mean,'damages_median1':np.median,'damages_sd1':np.std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_table = df.pivot_table(values=['Was_snowboard_sold_McNeil_defective_14'], index=[\"Was_snowboard_sold_McNeil_defective_14\",\"Is_substantial_factor_McNeil_injuries_14\"],aggfunc=np.average)\n",
    "print(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Null Checking\n",
    "any(df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jury_data1.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Test code to convert currency in word to integer value \n",
    "#for i in df['']\n",
    "newdf = df.filter(['What non-economic damages did Connor McNeil suffer? (in dollars)','Please write your answer to the preceding damages question in words (quality check)..2'], axis=1)\n",
    "newdf['Newcol'] = 0\n",
    "newdf.columns = ['a', 'b', 'c']\n",
    "newdf.head()\n",
    "\n",
    "from word2number import w2n\n",
    "a = \"2 hundred thousand dollars\"\n",
    "lst = list(range(1,1000))\n",
    "t = a.split\n",
    "print(t)\n",
    "try:\n",
    "    print(w2n.word_to_num(a))\n",
    "except:\n",
    "    print(\"error occur\")\n",
    "df.columns\n",
    "\n",
    "for index,row in newdf.iterrows():\n",
    "    word = row['b']\n",
    "    print(row['b'])\n",
    "    try:\n",
    "        row['c'] = w2n.word_to_num(word)\n",
    "    except:\n",
    "        print(\"error occur\", word)\n",
    "newdf['c'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
