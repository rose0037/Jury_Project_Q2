{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "################### Starting code written by Mayuri ###################\n",
    "\n",
    "\n",
    "data = pd.read_csv('jury_data.csv', encoding= 'ISO-8859-1', skiprows=[0,2])\n",
    "data.rename(columns={\"Was defendant Mesa Management negligent?\": \"Mesa_Negligent\", \n",
    "                         \"Was Mesa Management's negligence a substantial factor in causing harm to  Mackenzie Dunn?\":\"Liability\",\n",
    "                         \"What are the total damages that you find that MacKenzie Dunn sufferered?\":\"damages\" ,\n",
    "                         \"What is your sex?\": \"gender\",\n",
    "                         \"Please write your answer to the preceding damages question in words (quality check).\":\"damages_word\",\n",
    "                         \"What percentage of responsibility for Mackenzie Dunn's injuries was each party responsible for? (Answers should add up to 100%) - Mesa Management Co\":\"Mesa_reponsible_percentage\",\n",
    "                         \"Path\":\"Scenario\",\n",
    "                         \"Was MacKenzie Dunn negligent?\":\"Dunn_negligent\",\n",
    "                         \"Unnamed: 63\":\"perc_calc\"\n",
    "                         },inplace=True)\n",
    "data['mm_perc'] = np.where(data['Mesa_reponsible_percentage']>=1, data['perc_calc'], data['Mesa_reponsible_percentage'])\n",
    "req_data = pd.DataFrame(data[[\"Mesa_Negligent\",\"damages\",\"Liability\",\n",
    "                 \"gender\",\n",
    "                 \"damages_word\",\n",
    "                 \"Scenario\",\"Dunn_negligent\",\"perc_calc\",\"Start Date\",\"End Date\",\"mm_perc\"]])\n",
    "\n",
    "\n",
    "req_data['Liability'] = req_data['Liability'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "print(req_data.columns)\n",
    "\n",
    "\n",
    "\n",
    "print(pd.isnull(req_data).any())\n",
    "print(pd.isnull(req_data['Scenario']).any())\n",
    "req_data = req_data[np.isfinite(data['Scenario'])]\n",
    "print(pd.isnull(req_data['Scenario']).any())\n",
    "req_data['damages'].fillna(0,inplace=True)\n",
    "req_data['damages_word'].fillna(0,inplace=True)\n",
    "req_data['mm_perc'].fillna(1,inplace=True)\n",
    "req_data['perc_calc'].fillna(0,inplace=True)\n",
    "#Dropping the last two rows which has null values\n",
    "#data[pd.isnull(data['Path'])]\n",
    "#data['Path']=data.Path.dropna(inplace= True)\n",
    "#data[pd.isnull(data['Path'])]\n",
    "print(pd.isnull(req_data).any())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Changing data types of columns\n",
    "req_data['End Date'] = pd.to_datetime(data['End Date'])\n",
    "req_data['Start Date'] = pd.to_datetime(data['Start Date'])\n",
    "req_data['Scenario']= req_data.Scenario.astype(int)\n",
    "req_data['Liability']= req_data.Liability.astype(int)\n",
    "req_data.dtypes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Getting the id of the column\n",
    "data.columns.get_loc(\"Liability\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Damages and perc_calc column\n",
    "print(req_data.isnull().any())\n",
    "req_data['damages'] = req_data['damages'].str.replace(',', '')\n",
    "req_data['perc_calc'] = req_data['perc_calc'].str.replace('$', '')\n",
    "req_data['perc_calc'] = req_data['perc_calc'].str.replace(',', '')\n",
    "req_data['perc_calc'] = req_data['perc_calc'].str.replace('-', '')\n",
    "req_data['perc_calc'] = req_data['perc_calc'].str.replace(\"  \", '')\n",
    "req_data['mm_perc'] = req_data['mm_perc'].str.replace(\"$\", '')\n",
    "req_data['mm_perc'] = req_data['mm_perc'].str.replace(\",\", '')\n",
    "req_data['mm_perc'] = req_data['mm_perc'].str.replace(\"  \", '')\n",
    "#req_data.damages=pd.to_numeric(req_data['damages'].str.replace(',', ''))\n",
    "#req_data.perc_calc=pd.to_numeric(req_data.perc_calc)\n",
    "#print(req_data.isnull().any())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "req_data.damages=pd.to_numeric(req_data['damages'])\n",
    "req_data.perc_calc=pd.to_numeric(req_data.perc_calc)\n",
    "req_data['damages'].fillna(0,inplace=True)  \n",
    "req_data['mm_perc'].fillna(1,inplace=True)\n",
    "req_data['perc_calc'].fillna(0,inplace=True)\n",
    "#print(req_data.damages)\n",
    "print(req_data.isnull().any())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(req_data[pd.isnull(req_data['Dunn_negligent'])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#EDA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "req_data['winrate_percentage']=req_data.Liability\n",
    "req_data['damages_mean']=req_data.damages+req_data.perc_calc\n",
    "req_data['damages_median']=req_data.damages\n",
    "req_data['damages_sd']=req_data.damages\n",
    "\n",
    "winrate_damages_expected=req_data.groupby('Scenario').aggregate(\n",
    "    {'winrate_percentage': np.mean, 'damages_mean': np.mean,'damages_median':np.median,'damages_sd':np.std})\n",
    "\n",
    "\n",
    "winrate_damages_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#req_data['winrate_percentage']=np.mean(req_data.Juror_Response)\n",
    "#print(req_data)\n",
    "req_data['mm_perc'].fillna(1,inplace=True)\n",
    "req_data['damages_mean1']=req_data.damages*pd.to_numeric(req_data.mm_perc)\n",
    "req_data['damages_median1']=req_data.damages\n",
    "req_data['damages_sd1']=req_data.damages\n",
    "#print(req_data.mm_perc)\n",
    "\n",
    "winrate_damages_plaintiffwin=req_data.loc[(req_data['Dunn_negligent']=='No') & (req_data['Liability']==1)].groupby('Scenario').aggregate({'damages_mean1': np.mean,'damages_median1':np.median,'damages_sd1':np.std})\n",
    "\n",
    "\n",
    "winrate_damages_plaintiffwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.factorplot(x='Scenario', y='damages', kind='box',data=req_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pd.crosstab(data.Scenario,data.Liability).plot(kind='bar')\n",
    "plt.title('Purchase Frequency for Job Title')\n",
    "plt.xlabel('Scenario')\n",
    "plt.ylabel('Liability')\n",
    "plt.savefig('Juror Response per each Scenario')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = req_data['Scenario']\n",
    "b = req_data['Liability']\n",
    "pd.crosstab(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Starting code written by Rosy ###################\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read jury data \n",
    "jury_data1 = pd.read_csv('Low_Anchor.tsv', encoding= 'ISO-8859-1',skiprows=[0,2])\n",
    "jury_data1.head(5)\n",
    "\n",
    "## To describe columns\n",
    "jury_data1.columns\n",
    "\n",
    "jury_data1.describe()\n",
    "\n",
    "# To check data type of each columns.\n",
    "print(data.dtypes)\n",
    "\n",
    "## Changing Data type\n",
    "data['End Date'] = pd.to_datetime(data['End Date'])\n",
    "data['Start Date'] = pd.to_datetime(data['Start Date'])\n",
    "data.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stating code for quater 2\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.read_csv('Low_Anchor.tsv', sep='\\t+',skiprows=[0,2, 4]+list(range(1,1614,2)) + [1614], names = ['StartDate', 'EndDate',\n",
    "       'ResponseType', \n",
    "       'IP Address', \n",
    "       'Progress', \n",
    "       'Duration',\n",
    "       'Finished',\n",
    "       'RecordedDate',\n",
    "       'ResponseID', \n",
    "       'RecipientLastName','RecipientFirstName','RecipientEmail',\n",
    "       'ExternalDataReference','LocationLatitude', 'LocationLongitude',\n",
    "       'DistributionChannel', 'UserLanguage', 'Participation_in_this_project.',\n",
    "       'Browser Meta Info - Browser',\n",
    "       'Browser Meta Info - Version',\n",
    "       'Browser Meta Info - Operating System',\n",
    "       'Browser Meta Info - Resolution',\n",
    "       'What number did you hear?',\n",
    "       'What word did you see?',\n",
    "       'What is your sex?',\n",
    "       'How old are you?',\n",
    "       'Which of the following best describes your ethnicity?',\n",
    "       'Are you Spanish/Hispanic/Latino',\n",
    "       'What is the highest degree or level of school you have completed?',\n",
    "       'This is an attention check.  Select 200.',\n",
    "       'Which of the following best describes your total household income?',\n",
    "       'Where would you place yourself on this scale?',\n",
    "       'What is your zip code?',\n",
    "       'Timing - First Click','Timing - Last Click','Timing - Page Submit', 'Timing - Click Count',\n",
    "       'Timing - First Click.1', 'Timing - Last Click.1', 'Timing - Page Submit.1',\n",
    "       'Timing - Click Count.1', 'Timing - First Click.2','Timing - Last Click.2',\n",
    "       'Timing - Page Submit.2','Timing - Click Count.2','Timing - First Click.3','Timing - Last Click.3',\n",
    "       'Timing - Page Submit.3','Timing - Click Count.3','Timing - First Click.4', 'Timing - Last Click.4',\n",
    "       'Timing - Page Submit.4','Timing - Click Count.4', 'Timing - First Click.5', 'Timing - Last Click.5',\n",
    "       'Timing - Page Submit.5','Timing - Click Count.5', 'Timing - First Click.6', 'Timing - Last Click.6',\n",
    "       'Timing - Page Submit.6',  'Timing - Click Count.6', 'Timing - First Click.7','Timing - Last Click.7',\n",
    "       'Timing - Page Submit.7',  'Timing - Click Count.7',\n",
    "       'Identify the statement that correctly describes the facts of this case. (This is the attention check)',\n",
    "       'Was the Carve 3000 snowboard X5 sold Connor McNeil defective?',\n",
    "       \"Was the defect(s) a substantial factor in causing Connor McNeil's injuries?\",\n",
    "       'non_economic_damages_suffered',\n",
    "       'Please write your answer to the preceding damages question in words (quality check).',\n",
    "       'Was Connor McNeil negligent?',\n",
    "       'Was Connor McNeil negligence a substantial factor in causing her own injuries?',\n",
    "       'What percentage of responsibility for Connor McNeil injuries was each party responsible for? (Answers should add up to 100%) - X5',\n",
    "       'What percentage of responsibility for Connor McNeil injuries was each party responsible for? (Answers should add up to 100%) - Connor McNeil',\n",
    "       'Was the Carve 3000 snowboard X5 sold Connor McNeil defective?.1',\n",
    "       \"Was the defect(s) a substantial factor in causing Connor McNeil's injuries?.1\",\n",
    "       'What economic damages did Connor McNeil suffer?  (in dollars)',\n",
    "       'Please write your answer to the preceding damages question in words (quality check)..1',\n",
    "       'What non-economic damages did Connor McNeil suffer? (in dollars)',\n",
    "       'Please write your answer to the preceding damages question in words (quality check)..2',\n",
    "       'Please explain why you arrived at your decision? (50 character minimum)',\n",
    "       'Did the fact that X5 added core inserts to the later Carve 3000 model, affect your view as to whether the original Carve 3000 was defective?',\n",
    "       'Were you able to ignore the  fact that X5 added core inserts to the later Carve 3000 model when deciding whether the original Carve 3000 was defective?',\n",
    "       'Path'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "## Data type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check column names \n",
    "print (df.columns)\n",
    "\n",
    "# Null Checking\n",
    "any(df.isnull().any())\n",
    "\n",
    "## replacing hexadecimal value of damages to ''\n",
    "for i in range(len(df['non_economic_damages_suffered'])):\n",
    "    df['non_economic_damages_suffered'].values[i] = df['non_economic_damages_suffered'].values[i].replace('\\x00','')\n",
    "    df['Path'].values[i] = df['Path'].values[i].replace('\\x00','') ;  \n",
    "    df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].values[i] =  df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].values[i].replace('\\x00','') ;  \n",
    "    \n",
    "# replacing NAN value to 0 for path to change the datatype to int\n",
    "df['Path'].fillna(0,inplace = True)\n",
    "\n",
    "\n",
    "df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].fillna(-1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing Data type\n",
    "df.StartDate = pd.to_datetime(df.StartDate)\n",
    "df.EndDate = pd.to_datetime(df.EndDate) \n",
    "df.non_economic_damages_suffered = pd.to_numeric(df.non_economic_damages_suffered)\n",
    "df.Path =  df.Path.astype(int)\n",
    "df.dtypes\n",
    "# everything is nice\n",
    "\n",
    "#df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'] = df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?'].astype(int)\n",
    "df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?']\n",
    "\n",
    "t = map( filter(lambda x: len(str(x)) == 1, df['non_economic_damages_suffered'].values),0)\n",
    "\n",
    "## To merge both data set(work in progress): \n",
    "jury_data1.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test code to convert currency in word to integer value (work in progress): \n",
    "\n",
    "newdf = df.filter(['What non-economic damages did Connor McNeil suffer? (in dollars)','Please write your answer to the preceding damages question in words (quality check)..2'], axis=1)\n",
    "newdf['Newcol'] = 0\n",
    "newdf.columns = ['a', 'b', 'c']\n",
    "newdf.head()\n",
    "\n",
    "from word2number import w2n\n",
    "a = \"2 hundred thousand dollars\"\n",
    "lst = list(range(1,1000))\n",
    "t = a.split\n",
    "print(t)\n",
    "try:\n",
    "    print(w2n.word_to_num(a))\n",
    "except:\n",
    "    print(\"error occur\")\n",
    "df.columns\n",
    "\n",
    "for index,row in newdf.iterrows():\n",
    "    word = row['b']\n",
    "    print(row['b'])\n",
    "    try:\n",
    "        row['c'] = w2n.word_to_num(word)\n",
    "    except:\n",
    "        print(\"error occur\", word)\n",
    "newdf['c'].unique\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Path'],df['Was the Carve 3000 snowboard X5 sold Connor McNeil defective?']).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
